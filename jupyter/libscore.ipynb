{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libscore\n",
    "\n",
    "This library is a collection of tools to score and evaluate predictions and algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Evaluation Class\n",
    "\n",
    "We first define the class to evaluate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "class Score:\n",
    "    '''\n",
    "    This is a class to score and evaluate algorithms and predictions.\n",
    "    \n",
    "    Public methods:\n",
    "        correct:  returns the number of correct predictions,\n",
    "        accuracy: returns the accuracy of the predictions,\n",
    "        error:    returns the difference between the true values and the predictions\n",
    "        error2:   returns the squared difference between the true values and the predictions\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 y_true,\n",
    "                 y_pred,\n",
    "                 rounding=None\n",
    "                ):\n",
    "        '''\n",
    "        Constructor of the class.\n",
    "        \n",
    "        Required arguments:\n",
    "            y_true:   the true values,\n",
    "            y_pred:   the predicted values.\n",
    "        \n",
    "        Optional arguments:\n",
    "            rounding: the function used to approximate the predictions.\n",
    "        '''\n",
    "        \n",
    "        self.rounding = rounding\n",
    "        self.y_true   = np.array(y_true)\n",
    "        \n",
    "        # process the predictions\n",
    "        self.y_pred   = np.array(self.rounding(y_pred)) if self.rounding is not None else np.array(y_pred)\n",
    "        \n",
    "    def correct(self):\n",
    "        '''\n",
    "        Compute the number of correct predictions.\n",
    "        \n",
    "        Returns:\n",
    "            the number of correct predictions.\n",
    "        '''\n",
    "        \n",
    "        return np.sum(self.y_true == self.y_pred)\n",
    "    \n",
    "    def accuracy(self):\n",
    "        '''\n",
    "        Compute the accuracy of the predictions.\n",
    "        \n",
    "        Returns:\n",
    "            the accuracy.\n",
    "        '''\n",
    "        \n",
    "        return self.correct() / np.shape(self.y_true)[0]\n",
    "    \n",
    "    def error(self):\n",
    "        '''\n",
    "        Compute the difference between the true value and the predictions.\n",
    "        \n",
    "        Returns:\n",
    "            y_true - y_pred.\n",
    "        '''\n",
    "        \n",
    "        return self.y_true - self.y_pred\n",
    "    \n",
    "    def error2(self):\n",
    "        '''\n",
    "        Compute the squared difference of the errors.\n",
    "        \n",
    "        Returns:\n",
    "            (y_true - y_pred)**2\n",
    "        '''\n",
    "        return self.error()**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "We show some possible examples using the previous class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rint accuracy: 66.667%\n",
      "floor accuracy: 33.333%\n"
     ]
    }
   ],
   "source": [
    "y_true = [1,    10,   3,   5,   6,    3]\n",
    "y_pred = [1.01, 9.76, 1.2, 3.4, 6.49, 2.51]\n",
    "\n",
    "score_rint  = Score(y_true, y_pred, rounding=np.rint)\n",
    "score_floor = Score(y_true, y_pred, rounding=np.floor)\n",
    "\n",
    "print('{} accuracy: {:.3f}%'.format(score_rint.rounding.__name__, score_rint.accuracy()*100))\n",
    "print('{} accuracy: {:.3f}%'.format(score_floor.rounding.__name__, score_floor.accuracy()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Evaluation Class\n",
    "\n",
    "We then define a class to show the cross-validation results as given by a _sklearn_ interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewCV:\n",
    "    '''\n",
    "    This class retrieves and manipulates the cross-validation results of a Scikit estimator.\n",
    "    \n",
    "    Public methods:\n",
    "        results:         returns a Pandas dataframe with the complete cross-validation results,\n",
    "        best_results:    returns a Pandas dataframe with the best cross-validation results,\n",
    "        test_mean:       returns the mean value of the test score,\n",
    "        test_std:        returns the standard deviation of the test score.\n",
    "        \n",
    "    Attributes:\n",
    "        best_parameters: the best parameters of the estimator.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 estimator\n",
    "                ):\n",
    "        '''\n",
    "        Constructor of the class.\n",
    "        \n",
    "        Required arguments:\n",
    "            estimator: the Scikit estimator.\n",
    "        '''\n",
    "        \n",
    "        self.estimator       = estimator\n",
    "        self.best_parameters = self.estimator.best_params_\n",
    "        \n",
    "    def results(self):\n",
    "        '''\n",
    "        Retrieves the cross-validation results of the estimator.\n",
    "        \n",
    "        Returns:\n",
    "            a Pandas dataframe with the cross-validation results.\n",
    "        '''\n",
    "        \n",
    "        return pd.DataFrame(self.estimator.cv_results_)\n",
    "    \n",
    "    def best_results(self):\n",
    "        '''\n",
    "        Retrieves the cross-validation results of the estimator.\n",
    "        \n",
    "        Returns:\n",
    "            a Pandas dataframe with the cross-validation results.\n",
    "        '''\n",
    "        df = self.results()\n",
    "        return df.loc[df['params'] == self.best_parameters]\n",
    "    \n",
    "    def test_mean(self):\n",
    "        '''\n",
    "        Returns the mean of the test score.\n",
    "        \n",
    "        Return:\n",
    "            the mean of the test score.\n",
    "        '''\n",
    "        \n",
    "        return self.best_results().loc[:, 'mean_test_score'].values[0]\n",
    "    \n",
    "    def test_std(self):\n",
    "        '''\n",
    "        Returns the standard deviation of the test score.\n",
    "        \n",
    "        Return:\n",
    "            the mean of the test score.\n",
    "        '''\n",
    "        \n",
    "        return self.best_results().loc[:, 'std_test_score'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions\n",
    "\n",
    "We also implement a simpler functional interface of some functions in order to be able to call them in a simpler way inside other functions (e.g. the `make_scorer` in _Scikit_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred, rounding=None):\n",
    "    '''\n",
    "    Compute the accuracy (functional interface).\n",
    "    \n",
    "    Required arguments:\n",
    "        y_true: the true values,\n",
    "        y_pred: the predictions.\n",
    "        \n",
    "    Optional arguments:\n",
    "        rounding: the function used to approximate the predictions.\n",
    "    '''\n",
    "    \n",
    "    return Score(y_true=y_true,\n",
    "                 y_pred=y_pred,\n",
    "                 rounding=rounding\n",
    "                ).accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
